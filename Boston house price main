# Boston house price prediction


https://dsrajnor.wordpress.com/lp-v/


https://www.kaggle.com/code/shreayan98c/boston-house-price-prediction


/// information ///
1. Title: Boston Housing Data

2. Sources:
   (a) Origin:  This dataset was taken from the StatLib library which is
                maintained at Carnegie Mellon University.
   (b) Creator:  Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the 
                 demand for clean air', J. Environ. Economics & Management,
                 vol.5, 81-102, 1978.
   (c) Date: July 7, 1993

3. Past Usage:
   -   Used in Belsley, Kuh & Welsch, 'Regression diagnostics ...', Wiley, 
       1980.   N.B. Various transformations are used in the table on
       pages 244-261.
    -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.
       In Proceedings on the Tenth International Conference of Machine 
       Learning, 236-243, University of Massachusetts, Amherst. Morgan
       Kaufmann.

4. Relevant Information:

   Concerns housing values in suburbs of Boston.

5. Number of Instances: 506

6. Number of Attributes: 13 continuous attributes (including "class"
                         attribute "MEDV"), 1 binary-valued attribute.

7. Attribute Information:

    1. CRIM      per capita crime rate by town
    2. ZN        proportion of residential land zoned for lots over 
                 25,000 sq.ft.
    3. INDUS     proportion of non-retail business acres per town
    4. CHAS      Charles River dummy variable (= 1 if tract bounds 
                 river; 0 otherwise)
    5. NOX       nitric oxides concentration (parts per 10 million)
    6. RM        average number of rooms per dwelling
    7. AGE       proportion of owner-occupied units built prior to 1940
    8. DIS       weighted distances to five Boston employment centres
    9. RAD       index of accessibility to radial highways
    10. TAX      full-value property-tax rate per $10,000
    11. PTRATIO  pupil-teacher ratio by town
    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks 
                 by town
    13. LSTAT    % lower status of the population
    14. MEDV     Median value of owner-occupied homes in $1000's

8. Missing Attribute Values:  None.

























Sure, here are the key points from the provided assignment:

1. **Linear Regression**: 
   - It's a statistical approach to model the relationship between a dependent variable and one or more independent variables.
   - Assumes a linear relationship between variables and estimates coefficients to best fit the data.

2. **Deep Neural Network (DNN)**:
   - Modeled after the human brain, consisting of multiple layers of interconnected neurons.
   - Learns from data to make predictions or classifications.
   - Composed of input, hidden, and output layers, with each layer performing specific processing tasks.
   - Trained using backpropagation to adjust weights and biases based on prediction errors.

3. **Concept of Standardization**:
   - Standardization scales each feature to have zero mean and unit variance.
   - Ensures all features contribute equally to the model.
   - Common preprocessing step in machine learning.

4. **Splitting Data into Train and Test**:
   - Train set is used to train the model, while the test set is used to evaluate its performance.
   - Prevents overfitting by testing on unseen data.
   - Helps assess the model's generalization ability.

5. **Applications of Deep Neural Networks**:
   - Image and speech recognition.
   - Natural language processing.
   - Recommendation systems.
   - Financial forecasting.
   - Healthcare diagnostics.
   - Autonomous vehicles.
   - Drug discovery.
   - Game playing (e.g., AlphaGo).
   - Robotics.
These points summarize the core concepts and applications discussed in the assignment.





1. **Linear Regression**: It's like drawing a straight line through data points to understand their relationship. For example, predicting house prices based on factors like size and location.

2. **Deep Neural Network (DNN)**: Think of it as a brain-inspired model made up of layers of connected nodes. It learns from examples to make predictions, like recognizing objects in images or understanding speech.

3. **Standardization**: Making sure all data features play fair by giving them the same scale. Imagine everyone speaking the same language so that no one's voice gets drowned out.

4. **Splitting Data**: Imagine studying for a test. You practice with some questions (training data) but save some for the actual test (test data) to see how well you've really learned.

5. **Applications of DNNs**: They're like super-smart Swiss Army knives. They can do tons of things, from recognizing faces in photos to suggesting what to watch next on Netflix.


